/**
 * Script independiente para procesar un PDF completamente
 * Sin dependencias de nodemon ni duplicaciones
 */

import dotenv from 'dotenv';
dotenv.config();

import pkg from 'pg';
const { Pool } = pkg;
import { createRequire } from 'module';
const require = createRequire(import.meta.url);
const { PDFParse } = require('pdf-parse');
import { createClient } from '@supabase/supabase-js';
import crypto from 'crypto';

const pool = new Pool({
  connectionString: process.env.DATABASE_URL,
});

const supabase = createClient(
  process.env.SUPABASE_URL,
  process.env.SUPABASE_SERVICE_ROLE_KEY
);

/**
 * Limpia el texto extra√≠do del PDF removiendo metadatos, n√∫meros de p√°gina,
 * headers, footers y texto basura.
 */
function cleanPdfText(rawText) {
  let text = rawText;

  // 1. Remover l√≠neas que son solo n√∫meros (n√∫meros de p√°gina)
  text = text.replace(/^\s*\d+\s*$/gm, '');

  // 2. Remover patrones comunes de headers/footers
  // Ejemplo: "-- 1 of 65 --", "Page 1", etc.
  text = text.replace(/^--\s*\d+\s*of\s*\d+\s*--$/gm, '');
  text = text.replace(/^Page\s+\d+$/gmi, '');
  text = text.replace(/^P√°gina\s+\d+$/gmi, '');

  // 3. Remover URLs largas
  text = text.replace(/https?:\/\/[^\s]{50,}/g, '');

  // 4. Remover l√≠neas que son solo caracteres especiales o espacios
  text = text.replace(/^[\s\-_=*#]+$/gm, '');

  // 5. Remover m√∫ltiples saltos de l√≠nea consecutivos (m√°s de 2)
  text = text.replace(/\n{3,}/g, '\n\n');

  // 6. Remover espacios al inicio/final de cada l√≠nea
  text = text.split('\n').map(line => line.trim()).join('\n');

  // 7. Remover l√≠neas vac√≠as al inicio y final
  text = text.trim();

  // 8. Normalizar espacios m√∫ltiples
  text = text.replace(/ {2,}/g, ' ');

  return text;
}

/**
 * Divide texto en chunks respetando oraciones
 */
function chunkTextBySentence(text, maxLen = 1500) {
  const sentences = text.split(/([\.!?‚Ä¶]+)\s+/);
  const chunks = [];
  let buf = '';

  for (let i = 0; i < sentences.length; i += 2) {
    const sentence = (sentences[i] || '') + (sentences[i + 1] || '');
    
    if ((buf + ' ' + sentence).length > maxLen && buf.length > 0) {
      chunks.push(buf.trim());
      buf = sentence;
    } else {
      buf += (buf ? ' ' : '') + sentence;
    }
  }

  if (buf.trim()) {
    chunks.push(buf.trim());
  }

  return chunks;
}

/**
 * Procesar PDF: descargar, extraer texto, segmentar y guardar
 */
async function processPdf(libroId) {
  console.log(`\n=== üìö PROCESANDO LIBRO ${libroId} ===\n`);

  try {
    // 1. Obtener informaci√≥n del libro
    const libroResult = await pool.query(
      'SELECT id_libro, titulo, archivo FROM tbl_libros WHERE id_libro = $1',
      [libroId]
    );

    if (libroResult.rows.length === 0) {
      throw new Error(`Libro ${libroId} no encontrado`);
    }

    const libro = libroResult.rows[0];
    console.log(`üìñ Libro: ${libro.titulo}`);
    console.log(`üîó PDF URL: ${libro.archivo}\n`);

    if (!libro.archivo) {
      throw new Error('El libro no tiene archivo PDF asociado');
    }

    // 2. Crear o obtener documento
    let documentoId;
    const docResult = await pool.query(
      'SELECT id FROM tbl_documentos WHERE libro_id = $1',
      [libroId]
    );

    if (docResult.rows.length > 0) {
      documentoId = docResult.rows[0].id;
      console.log(`üìÑ Documento existente: ${documentoId}`);
      
      // Actualizar estado a procesando
      await pool.query(
        'UPDATE tbl_documentos SET estado = $1, updated_at = NOW() WHERE id = $2',
        ['procesando', documentoId]
      );
    } else {
      const newDoc = await pool.query(
        'INSERT INTO tbl_documentos (libro_id, estado) VALUES ($1, $2) RETURNING id',
        [libroId, 'procesando']
      );
      documentoId = newDoc.rows[0].id;
      console.log(`üìÑ Documento creado: ${documentoId}`);
    }

    // 3. Descargar PDF desde Supabase
    console.log('‚¨áÔ∏è  Descargando PDF...');
    const response = await fetch(libro.archivo);
    if (!response.ok) {
      throw new Error(`Error descargando PDF: ${response.statusText}`);
    }
    const pdfBuffer = Buffer.from(await response.arrayBuffer());
    console.log(`‚úÖ PDF descargado: ${(pdfBuffer.length / 1024).toFixed(2)} KB\n`);

    // 4. Extraer texto
    console.log('üìù Extrayendo texto del PDF...');
    const parser = new PDFParse({ data: pdfBuffer });
    const result = await parser.getText();
    const rawText = result.text;
    
    let totalPages = null;
    try {
      const info = await parser.getInfo();
      totalPages = info.numPages || null;
    } catch (e) {
      console.warn('‚ö†Ô∏è  No se pudo obtener n√∫mero de p√°ginas');
    }
    
    await parser.destroy();

    if (!rawText || rawText.trim().length === 0) {
      throw new Error('No se pudo extraer texto del PDF');
    }

    console.log(`‚úÖ Texto RAW extra√≠do: ${rawText.length.toLocaleString()} caracteres`);
    
    // 4.5. Limpiar texto (remover metadatos, n√∫meros de p√°gina, etc.)
    console.log('üßπ Limpiando metadatos del PDF...');
    const cleanedText = cleanPdfText(rawText);
    const fullText = cleanedText;
    
    console.log(`‚úÖ Texto limpio: ${fullText.length.toLocaleString()} caracteres (removidos ${(rawText.length - fullText.length).toLocaleString()})`);
    if (totalPages) console.log(`   P√°ginas: ${totalPages}`);
    
    // Contar palabras
    const palabras = fullText.trim().split(/\s+/).filter(p => p.length > 0);
    console.log(`   Palabras: ${palabras.length.toLocaleString()}\n`);

    // 5. Generar hash del texto
    const textHash = crypto.createHash('sha256').update(fullText).digest('hex');

    // 6. Segmentar texto
    console.log('‚úÇÔ∏è  Segmentando texto en chunks...');
    const chunks = chunkTextBySentence(fullText, 1500);
    console.log(`‚úÖ Generados ${chunks.length} segmentos\n`);

    // 7. Limpiar segmentos anteriores
    console.log('üßπ Limpiando segmentos anteriores...');
    const deleteResult = await pool.query(
      'DELETE FROM tbl_segmentos WHERE documento_id = $1',
      [documentoId]
    );
    console.log(`   Eliminados: ${deleteResult.rowCount} segmentos antiguos\n`);

    // 8. Insertar segmentos nuevos
    console.log('üíæ Guardando segmentos en la base de datos...');
    let currentOffset = 0;

    for (let i = 0; i < chunks.length; i++) {
      const chunk = chunks[i];
      const startChar = currentOffset;
      const endChar = currentOffset + chunk.length;
      const segmentHash = crypto.createHash('sha256').update(chunk).digest('hex');

      // Estimar p√°ginas
      let pageStart = null;
      let pageEnd = null;
      if (totalPages && totalPages > 0) {
        const avgCharsPerPage = fullText.length / totalPages;
        pageStart = Math.floor(startChar / avgCharsPerPage) + 1;
        pageEnd = Math.ceil(endChar / avgCharsPerPage);
      }

      await pool.query(
        `INSERT INTO tbl_segmentos 
        (documento_id, orden, pagina_inicio, pagina_fin, char_inicio, char_fin, texto, texto_hash)
        VALUES ($1, $2, $3, $4, $5, $6, $7, $8)`,
        [documentoId, i, pageStart, pageEnd, startChar, endChar, chunk, segmentHash]
      );

      currentOffset = endChar + 1;

      // Progreso cada 10 segmentos
      if ((i + 1) % 10 === 0 || i === chunks.length - 1) {
        process.stdout.write(`   Progreso: ${i + 1}/${chunks.length} segmentos\r`);
      }
    }

    console.log(`\n‚úÖ ${chunks.length} segmentos guardados exitosamente\n`);

    // 9. Actualizar documento con estado final
    await pool.query(
      `UPDATE tbl_documentos 
       SET estado = $1, 
           texto_hash = $2, 
           total_caracteres = $3, 
           total_segmentos = $4,
           updated_at = NOW()
       WHERE id = $5`,
      ['listo', textHash, fullText.length, chunks.length, documentoId]
    );

    // 10. Actualizar palabras en tbl_libros
    await pool.query(
      'UPDATE tbl_libros SET palabras = $1 WHERE id_libro = $2',
      [palabras.length, libroId]
    );

    console.log('‚ïê'.repeat(60));
    console.log('‚úÖ PROCESAMIENTO COMPLETADO EXITOSAMENTE');
    console.log('‚ïê'.repeat(60));
    console.log(`üìñ Libro: ${libro.titulo}`);
    console.log(`üìä Estad√≠sticas:`);
    console.log(`   - Caracteres: ${fullText.length.toLocaleString()}`);
    console.log(`   - Palabras: ${palabras.length.toLocaleString()}`);
    console.log(`   - Segmentos: ${chunks.length}`);
    console.log(`   - Hash: ${textHash.substring(0, 16)}...`);
    console.log('‚ïê'.repeat(60));

    return {
      success: true,
      libro_id: libroId,
      documento_id: documentoId,
      caracteres: fullText.length,
      palabras: palabras.length,
      segmentos: chunks.length,
    };

  } catch (error) {
    console.error('\n‚ùå ERROR PROCESANDO PDF:', error.message);
    
    // Intentar marcar documento como error
    try {
      await pool.query(
        'UPDATE tbl_documentos SET estado = $1, updated_at = NOW() WHERE libro_id = $2',
        ['error', libroId]
      );
    } catch (e) {
      // Ignorar error al actualizar estado
    }

    throw error;
  }
}

// Ejecutar
const libroId = parseInt(process.argv[2]) || 83;

processPdf(libroId)
  .then((result) => {
    console.log('\nüéâ Proceso finalizado exitosamente\n');
    pool.end();
    process.exit(0);
  })
  .catch((error) => {
    console.error('\nüí• Proceso fall√≥:', error.message);
    pool.end();
    process.exit(1);
  });
